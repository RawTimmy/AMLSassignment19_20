{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2grey\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"Datasets/celeba/labels.csv\", index_col=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get and preprocess(crop or resize) the images\n",
    "def resize_get_image(row_id, root=\"Datasets/celeba/img\"):\n",
    "    # Open Image\n",
    "    file_name = \"{}.jpg\".format(row_id)\n",
    "    file_path = os.path.join(root, file_name)\n",
    "    img_ori = Image.open(file_path)\n",
    "    \n",
    "    # Cropped Image Parameters(Assuming all faces are in the middle 64x128)\n",
    "    left, right = 57, 121\n",
    "    top, bot = 45, 173\n",
    "    img_resize = img_ori.crop((left, top, right, bot))\n",
    "    \n",
    "    return np.array(img_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(img):\n",
    "    color_features = img.flatten()\n",
    "    img_grey = rgb2grey(img)\n",
    "    hog_feartures = hog(img_grey, block_norm=\"L2-Hys\", pixels_per_cell=(16,16),cells_per_block=(2,2))\n",
    "    flat_features = np.hstack(color_features)\n",
    "    return flat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  0\n",
      "Done:  1000\n",
      "Done:  2000\n",
      "Done:  3000\n",
      "Done:  4000\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing the features\n",
    "def create_feature_matrix(label_dataframe):\n",
    "    feature_list = []\n",
    "    i = 0\n",
    "    for img_id in label_dataframe.index:\n",
    "        img = resize_get_image(img_id)\n",
    "        image_features = create_features(img)\n",
    "        feature_list.append(image_features)\n",
    "        if(i % 1000 == 0):\n",
    "            print(\"Done: \", i)\n",
    "        i+=1\n",
    "    \n",
    "    feature_matrix = np.array(feature_list)\n",
    "    return feature_matrix\n",
    "\n",
    "feature_matrix = create_feature_matrix(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix Shape is:  (5000, 24576)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rawtimmy/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Matrix Shape is:  (5000, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Matrix Shape is: \", feature_matrix.shape)\n",
    "\n",
    "ss = StandardScaler()\n",
    "people_stand = ss.fit_transform(feature_matrix)\n",
    "\n",
    "pca = PCA()\n",
    "people_pca = pca.fit_transform(people_stand)\n",
    "print(\"PCA Matrix Shape is: \", people_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset - Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1782\n",
       " 1    1718\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(people_pca)\n",
    "y = pd.Series(labels.gender.values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=1234123)\n",
    "\n",
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear', probability=True, random_state=42)\n",
    "gender_model = svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy is:  0.8973333333333333\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy is: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP - Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68984559\n",
      "Iteration 2, loss = 0.39215813\n",
      "Iteration 3, loss = 0.30616732\n",
      "Iteration 4, loss = 0.26079627\n",
      "Iteration 5, loss = 0.22840465\n",
      "Iteration 6, loss = 0.20511576\n",
      "Iteration 7, loss = 0.18645466\n",
      "Iteration 8, loss = 0.17110500\n",
      "Iteration 9, loss = 0.15656403\n",
      "Iteration 10, loss = 0.14414799\n",
      "Iteration 11, loss = 0.13462009\n",
      "Iteration 12, loss = 0.12438311\n",
      "Iteration 13, loss = 0.11646397\n",
      "Iteration 14, loss = 0.10700429\n",
      "Iteration 15, loss = 0.10073194\n",
      "Iteration 16, loss = 0.09579492\n",
      "Iteration 17, loss = 0.08912325\n",
      "Iteration 18, loss = 0.08331787\n",
      "Iteration 19, loss = 0.07862276\n",
      "Iteration 20, loss = 0.07353616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rawtimmy/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='sgd', \n",
    "                    activation='relu', \n",
    "                    alpha=1e-4, \n",
    "                    hidden_layer_sizes=(50,50), \n",
    "                    random_state=1, \n",
    "                    max_iter=20, \n",
    "                    verbose=10, \n",
    "                    learning_rate_init=0.001)\n",
    "gender_mlp_model = mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender MLP Model Acc: 0.9133333333333333\n",
      "No. Layers: 4\n",
      "No. Iterations: 20\n",
      "Loss: 0.07353615707748115\n",
      "Output Activation Function: logistic\n"
     ]
    }
   ],
   "source": [
    "print(\"Gender MLP Model Acc: \" + str(mlp.score(X_test, y_test)))\n",
    "print(\"No. Layers: \" + str(mlp.n_layers_))\n",
    "print(\"No. Iterations: \" + str(mlp.n_iter_))\n",
    "print(\"Loss: \" + str(mlp.loss_))\n",
    "print(\"Output Activation Function: \" + str(mlp.out_activation_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset - Smiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1753\n",
       " 1    1747\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smile = pd.DataFrame(people_pca)\n",
    "y_smile = pd.Series(labels.smiling.values)\n",
    "X_smile_train, X_smile_test, y_smile_train, y_smile_test = train_test_split(X_smile, y_smile, test_size = .3, random_state=1234123)\n",
    "\n",
    "pd.Series(y_smile_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - Smiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_smile = SVC(kernel='linear', probability=True, random_state=42)\n",
    "smile_model = svm_smile.fit(X_smile_train, y_smile_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy is:  0.8466666666666667\n"
     ]
    }
   ],
   "source": [
    "y_smile_pred = svm_smile.predict(X_smile_test)\n",
    "\n",
    "accuracy_smile = accuracy_score(y_smile_test, y_smile_pred)\n",
    "print(\"Model Accuracy is: \", accuracy_smile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP - Smiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.71070306\n",
      "Iteration 2, loss = 0.42078322\n",
      "Iteration 3, loss = 0.33774067\n",
      "Iteration 4, loss = 0.29315993\n",
      "Iteration 5, loss = 0.26267296\n",
      "Iteration 6, loss = 0.24044985\n",
      "Iteration 7, loss = 0.22377056\n",
      "Iteration 8, loss = 0.20652556\n",
      "Iteration 9, loss = 0.19473451\n",
      "Iteration 10, loss = 0.18184694\n",
      "Iteration 11, loss = 0.17201466\n",
      "Iteration 12, loss = 0.16207474\n",
      "Iteration 13, loss = 0.15386548\n",
      "Iteration 14, loss = 0.14571056\n",
      "Iteration 15, loss = 0.13868039\n",
      "Iteration 16, loss = 0.13262778\n",
      "Iteration 17, loss = 0.12545761\n",
      "Iteration 18, loss = 0.11905927\n",
      "Iteration 19, loss = 0.11356846\n",
      "Iteration 20, loss = 0.10924265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rawtimmy/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp_smile = MLPClassifier(solver='sgd', \n",
    "                    activation='relu', \n",
    "                    alpha=1e-4, \n",
    "                    hidden_layer_sizes=(50,50), \n",
    "                    random_state=1, \n",
    "                    max_iter=20, \n",
    "                    verbose=10, \n",
    "                    learning_rate_init=0.001)\n",
    "smile_mlp_model = mlp_smile.fit(X_smile_train, y_smile_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smiling MLP Model Acc: 0.8626666666666667\n",
      "No. Layers: 4\n",
      "No. Iterations: 20\n",
      "Loss: 0.1092426542437643\n",
      "Output Activation Function: logistic\n"
     ]
    }
   ],
   "source": [
    "print(\"Smiling MLP Model Acc: \" + str(mlp_smile.score(X_smile_test, y_smile_test)))\n",
    "print(\"No. Layers: \" + str(mlp_smile.n_layers_))\n",
    "print(\"No. Iterations: \" + str(mlp_smile.n_iter_))\n",
    "print(\"Loss: \" + str(mlp_smile.loss_))\n",
    "print(\"Output Activation Function: \" + str(mlp_smile.out_activation_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_weights_and_biases():\n",
    "    n_hidden_1 = 2048\n",
    "    n_hidden_2 = 2048\n",
    "    \n",
    "    X = tf.placeholder(\"float\", [None, 68, 2])\n",
    "    Y = tf.placeholder(\"float\", [None, 2])\n",
    "    \n",
    "    img_flat = tf.contrib.layers.flatten(X)\n",
    "    \n",
    "    stddev = 0.01\n",
    "    \n",
    "    weights = {\n",
    "        'hidden_layer1': tf.Variable(tf.random_normal([68*2, n_hidden_1], stddev = stddev)),\n",
    "        'hidden_layer2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev = stddev)),\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden_2, 2], stddev=stddev))\n",
    "    }\n",
    "    \n",
    "    biases = {\n",
    "        'bias_layer1': tf.Variable(tf.random_normal([n_hidden_1], stddev = stddev)),\n",
    "        'bias_layer2': tf.Variable(tf.random_normal([n_hidden_2], stddev = stddev)),\n",
    "        'out': tf.Variable(tf.random_normal([2], stddev = stddev))\n",
    "    }\n",
    "    \n",
    "    return weights, biases, X, Y, img_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_mlp():\n",
    "    weights, biases, X, Y, img_flat = allocate_weights_and_biases()\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(img_flat, weights['hidden_layer1']), biases['bias_layer1'])\n",
    "    layer_1 = tf.math.sigmoid(layer_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['hidden_layer2']), biases['bias_layer2'])\n",
    "    layer_2 = tf.math.sigmoid(layer_2)\n",
    "    \n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 10000 and 136 for 'MatMul_3' (op: 'MatMul') with input shapes: [5000,10000], [136,2048].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1628\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1629\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 10000 and 136 for 'MatMul_3' (op: 'MatMul') with input shapes: [5000,10000], [136,2048].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-43c7822221a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# training_images, training_labels, test_images, test_labels = get_data()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# define loss and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-48860fdf78b6>\u001b[0m in \u001b[0;36mmodel_mlp\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallocate_weights_and_biases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlayer_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hidden_layer1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias_layer1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlayer_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2055\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2057\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   4558\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   4559\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4560\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   4561\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4562\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 instructions)\n\u001b[0;32m--> 488\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3274\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1792\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 10000 and 136 for 'MatMul_3' (op: 'MatMul') with input shapes: [5000,10000], [136,2048]."
     ]
    }
   ],
   "source": [
    "# learning parameters\n",
    "learning_rate = 0.00001\n",
    "training_epochs = 500\n",
    "\n",
    "# display training accuracy every ..\n",
    "display_accuracy_step = 2\n",
    "    \n",
    "\n",
    "#\n",
    "X_diu = pd.DataFrame(people_pca)\n",
    "y_diu = pd.Series(labels.gender.values)\n",
    "training_images, test_images, training_labels, test_labels = train_test_split(X_diu, y_diu, test_size = .3, random_state=1234123)\n",
    "#\n",
    "# training_images, training_labels, test_images, test_labels = get_data()\n",
    "logits, X, Y = model_mlp()\n",
    "\n",
    "# define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# define training graph operation\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# graph operation to initialize all variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (3500, 5000) for Tensor 'Placeholder:0', which has shape '(?, 68, 2)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3a8f19fb9e37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;31m# run optimization operation (backprop) and cost operation (to get loss value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             _, cost = sess.run([train_op, loss_op], feed_dict={X: training_images,\n\u001b[0;32m----> 9\u001b[0;31m                                                                Y: training_labels})\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# Display logs per epoch step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (3500, 5000) for Tensor 'Placeholder:0', which has shape '(?, 68, 2)'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "        # run graph weights/biases initialization op\n",
    "        sess.run(init)\n",
    "        # begin training loop ..\n",
    "        for epoch in range(training_epochs):\n",
    "            # run optimization operation (backprop) and cost operation (to get loss value)\n",
    "            _, cost = sess.run([train_op, loss_op], feed_dict={X: training_images,\n",
    "                                                               Y: training_labels})\n",
    "\n",
    "            # Display logs per epoch step\n",
    "            print(\"Epoch:\", '%04d' % (epoch + 1), \"cost={:.9f}\".format(cost))\n",
    "                \n",
    "            if epoch % display_accuracy_step == 0:\n",
    "                pred = tf.nn.softmax(logits)  # Apply softmax to logits\n",
    "                correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "\n",
    "                # calculate training accuracy\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "                print(\"Accuracy: {:.3f}\".format(accuracy.eval({X: training_images, Y: training_labels})))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        # -- Define and run test operation -- #\n",
    "        \n",
    "        # apply softmax to output logits\n",
    "        pred = tf.nn.softmax(logits)\n",
    "        \n",
    "        #  derive inffered calasses as the class with the top value in the output density function\n",
    "        correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "        \n",
    "        # calculate accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        # run test accuracy operation ..\n",
    "        print(\"Test Accuracy:\", accuracy.eval({X: test_images, Y: test_labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def features_extraction_with_labels(root=\"Datasets/celeba\"):\n",
    "#     # Read labels from csv\n",
    "#     labels = pd.read_csv(root+\"labels.csv\", index_col=0, sep='\\t')\n",
    "    \n",
    "#     img_paths = [os.path.join(root, \"img\"+file_name) for file_name in os.listdir(root)]\n",
    "    \n",
    "#     if os.path.isdir(root+\"/img\"):\n",
    "#         img_features = []\n",
    "#         img_labels = []\n",
    "#         gender_labels_series = pd.Series(labels.gender.values)\n",
    "        \n",
    "#         for img_path in img_paths:\n",
    "#             file_no = img_path.split('/')[-1].split('.')[0]\n",
    "            \n",
    "#             img = image.img_to_array(image.load_img(img_path, \n",
    "#                                                     target_size=None, \n",
    "#                                                     interpolation='bicubic'))\n",
    "            \n",
    "#             features, _ = img_preprocessing(img)\n",
    "            \n",
    "#             if features is not None:\n",
    "#                 img_features.append(features) \n",
    "#                 img_labels.append(gender_labels_series[int(file_no)])\n",
    "    \n",
    "#     landmark_features = np.array(img_features)\n",
    "#     gender_labels_new = (np.array(img_labels) + 1) / 2\n",
    "    \n",
    "#     return landmark_featrues, gender_labels_new\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
